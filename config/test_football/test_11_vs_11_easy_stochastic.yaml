env_params:
  env_name: "football-11_vs_11_easy_stochastic"
  num_envs: 16

policy_params:
  lr: 0.000343
  train_iters: 2
  clip_param: 0.08
  target_kl: 0.01
  kl_coef: 0.2
  ent_coef: 0.003
  vf_loss_coef: 0.25
  clip_grads: 0.64

  nn_architecure: "impala_cnn_actor_critic"
  pool_size: [1, 1]
  resnet_filters: 
    - [16, 3, 1, 2]
    - [32, 3, 1, 2]
    - [32, 3, 1, 2]
    - [32, 3, 1, 2]
  activation: 
  output_activation: 
  kernel_initializer: 
  input_shape: [72, 96, 16]
  act_size: 19

train_params:
  trainer: "Proximal Policy Optimization"

  epochs: 10000000
  steps_per_epoch: 512
  num_mini_batches: 8
  gamma: 0.993
  lam: 0.95
  save_freq: 200

  restore_path: